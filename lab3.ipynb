{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "\n",
    "action = namedtuple('Action', ['pos1', 'pos2']) # pos1, pos2 are tuples of (x, y). pos1 is current position, pos2 is target position\n",
    "\n",
    "#Returns list of all available actions for \"0\" in the given state\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Randomizing: 100%|██████████| 500/500 [00:00<00:00, 293103.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 5, 8],\n",
       "       [3, 1, 7],\n",
       "       [6, 4, 2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns new state after performing the given action on the given state\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n",
    "\n",
    "\n",
    "RANDOMIZE_STEPS = 500\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "goal_state = state.copy()\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Manhattan Distance measures the total distance each tile is from its goal position\n",
    "def manhattan_distance(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    dist = 0\n",
    "    for x in range(PUZZLE_DIM):\n",
    "        for y in range(PUZZLE_DIM):\n",
    "            value = state[x, y]\n",
    "            if value == 0:\n",
    "                continue\n",
    "            goal_pos = np.argwhere(goal == value)[0]\n",
    "            dist += abs(x - goal_pos[0]) + abs(y - goal_pos[1])\n",
    "    return dist\n",
    "\n",
    "# The linear conflict heuristic extends the Manhattan Distance by adding 2 for each pair of tiles that are in their goal row/column but are in the wrong order\n",
    "def linear_conflict(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    md = manhattan_distance(state, goal)  # Use the previously defined Manhattan Distance\n",
    "    conflict = 0\n",
    "    size = state.shape[0]\n",
    "\n",
    "    for row in range(size):\n",
    "        goal_row = goal[row]\n",
    "        current_row = state[row]\n",
    "\n",
    "        # Count conflicts in the current row\n",
    "        for i in range(size):\n",
    "            for j in range(i + 1, size):\n",
    "                if current_row[i] in goal_row and current_row[j] in goal_row:\n",
    "                    if goal_row.tolist().index(current_row[i]) > goal_row.tolist().index(current_row[j]):\n",
    "                        conflict += 2  # Each conflict adds 2 to the heuristic\n",
    "\n",
    "    for col in range(size):\n",
    "        goal_col = goal[:, col]\n",
    "        current_col = state[:, col]\n",
    "\n",
    "        # Count conflicts in the current column\n",
    "        for i in range(size):\n",
    "            for j in range(i + 1, size):\n",
    "                if current_col[i] in goal_col and current_col[j] in goal_col:\n",
    "                    if goal_col.tolist().index(current_col[i]) > goal_col.tolist().index(current_col[j]):\n",
    "                        conflict += 2  # Each conflict adds 2 to the heuristic\n",
    "\n",
    "    return md + conflict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappop, heappush\n",
    "\n",
    "\n",
    "def solve_puzzle(start: np.ndarray, goal: np.ndarray) -> list[np.ndarray]:\n",
    "    start_tuple = tuple(start.flatten())\n",
    "    goal_tuple = tuple(goal.flatten())\n",
    "\n",
    "    open_set = []\n",
    "    heappush(open_set, (0, start_tuple))\n",
    "\n",
    "    came_from = {}\n",
    "    g_score = {start_tuple: 0}\n",
    "    f_score = {start_tuple: linear_conflict(start, goal)}\n",
    "\n",
    "    actions_evaluated = 0 #Used for evaluating cost\n",
    "\n",
    "    while open_set:\n",
    "        _, current = heappop(open_set)\n",
    "        current_state = np.array(current).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "\n",
    "        if current == goal_tuple:\n",
    "            path = []\n",
    "            while current:\n",
    "                path.append(np.array(current).reshape((PUZZLE_DIM, PUZZLE_DIM)))\n",
    "                current = came_from.get(current)\n",
    "            return path[::-1], actions_evaluated\n",
    "\n",
    "        for action in available_actions(current_state):\n",
    "            actions_evaluated += 1\n",
    "            neighbor_state = do_action(current_state, action)\n",
    "            neighbor_tuple = tuple(neighbor_state.flatten())\n",
    "            tentative_g_score = g_score[current] + 1\n",
    "\n",
    "            if tentative_g_score < g_score.get(neighbor_tuple, float('inf')):\n",
    "                came_from[neighbor_tuple] = current\n",
    "                g_score[neighbor_tuple] = tentative_g_score\n",
    "                f_score[neighbor_tuple] = tentative_g_score + linear_conflict(neighbor_state, goal)\n",
    "                heappush(open_set, (f_score[neighbor_tuple], neighbor_tuple))\n",
    "\n",
    "    return None, actions_evaluated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0:\n",
      "[[0 5 8]\n",
      " [3 1 7]\n",
      " [6 4 2]]\n",
      "Step 1:\n",
      "[[3 5 8]\n",
      " [0 1 7]\n",
      " [6 4 2]]\n",
      "Step 2:\n",
      "[[3 5 8]\n",
      " [1 0 7]\n",
      " [6 4 2]]\n",
      "Step 3:\n",
      "[[3 5 8]\n",
      " [1 7 0]\n",
      " [6 4 2]]\n",
      "Step 4:\n",
      "[[3 5 0]\n",
      " [1 7 8]\n",
      " [6 4 2]]\n",
      "Step 5:\n",
      "[[3 0 5]\n",
      " [1 7 8]\n",
      " [6 4 2]]\n",
      "Step 6:\n",
      "[[0 3 5]\n",
      " [1 7 8]\n",
      " [6 4 2]]\n",
      "Step 7:\n",
      "[[1 3 5]\n",
      " [0 7 8]\n",
      " [6 4 2]]\n",
      "Step 8:\n",
      "[[1 3 5]\n",
      " [7 0 8]\n",
      " [6 4 2]]\n",
      "Step 9:\n",
      "[[1 3 5]\n",
      " [7 4 8]\n",
      " [6 0 2]]\n",
      "Step 10:\n",
      "[[1 3 5]\n",
      " [7 4 8]\n",
      " [0 6 2]]\n",
      "Step 11:\n",
      "[[1 3 5]\n",
      " [0 4 8]\n",
      " [7 6 2]]\n",
      "Step 12:\n",
      "[[1 3 5]\n",
      " [4 0 8]\n",
      " [7 6 2]]\n",
      "Step 13:\n",
      "[[1 3 5]\n",
      " [4 8 0]\n",
      " [7 6 2]]\n",
      "Step 14:\n",
      "[[1 3 5]\n",
      " [4 8 2]\n",
      " [7 6 0]]\n",
      "Step 15:\n",
      "[[1 3 5]\n",
      " [4 8 2]\n",
      " [7 0 6]]\n",
      "Step 16:\n",
      "[[1 3 5]\n",
      " [4 0 2]\n",
      " [7 8 6]]\n",
      "Step 17:\n",
      "[[1 3 5]\n",
      " [4 2 0]\n",
      " [7 8 6]]\n",
      "Step 18:\n",
      "[[1 3 0]\n",
      " [4 2 5]\n",
      " [7 8 6]]\n",
      "Step 19:\n",
      "[[1 0 3]\n",
      " [4 2 5]\n",
      " [7 8 6]]\n",
      "Step 20:\n",
      "[[1 2 3]\n",
      " [4 0 5]\n",
      " [7 8 6]]\n",
      "Step 21:\n",
      "[[1 2 3]\n",
      " [4 5 0]\n",
      " [7 8 6]]\n",
      "Step 22:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Total actions in solution (quality): 22\n",
      "Total actions evaluated (cost): 385\n"
     ]
    }
   ],
   "source": [
    "solution, cost = solve_puzzle(state, goal_state)\n",
    "\n",
    "if solution:\n",
    "    for step, s in enumerate(solution):\n",
    "        print(f\"Step {step}:\")\n",
    "        print(s)\n",
    "        \n",
    "    quality = len(solution)-1\n",
    "    print(f\"Total actions in solution (quality): {quality}\")\n",
    "    print(f\"Total actions evaluated (cost): {cost}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No solution found.\")\n",
    "    print(f\"Total actions evaluated (cost): {cost}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
